{"version":3,"file":"grok.js","sourceRoot":"","sources":["../../../../lib/utils/llm/grok.ts"],"names":[],"mappings":";;;AAgBA,4BA0CC;;AA1DD,4DAA2B;AAC3B,4CAAsD;AAEtD,0CAAsD;AACtD,sCAA0C;AAE7B,QAAA,UAAU,GAAG;IACtB,WAAW,EAAE,eAAe;IAC5B,WAAW,EAAE,eAAe;CAC/B,CAAA;AAED,MAAM,SAAS,GAAG,IAAI,gBAAM,CAAC;IACzB,MAAM,EAAE,OAAO,CAAC,GAAG,CAAC,YAAY,IAAI,EAAE;IACtC,OAAO,EAAE,qBAAqB;CACjC,CAAC,CAAA;AAEK,KAAK,UAAU,QAAQ,CAAC,QAAyB;IACpD,IAAI,MAAM,GAAG,IAAI,CAAA;IACjB,IAAI,KAAK,GAAG,IAAI,CAAA;IAChB,MAAM,KAAK,GAAG,QAAQ,CAAC,KAAK,IAAI,kBAAU,CAAC,WAAW,CAAA;IAEtD,IAAI,CAAC;QACD,MAAM,UAAU,GAAG,MAAM,SAAS,CAAC,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC;YACvD,KAAK;YACL,KAAK,EAAE,IAAI;YACX,QAAQ,EAAE;gBACN;oBACI,IAAI,EAAE,QAAQ;oBACd,OAAO,EACH,6GAA6G;iBACpH;gBACD,EAAE,IAAI,EAAE,MAAM,EAAE,OAAO,EAAE,QAAQ,CAAC,MAAM,EAAE;aAC7C;YACD,eAAe,EAAE,IAAA,uBAAiB,EAAC,yBAAmB,EAAE,YAAY,CAAC;SACxE,CAAC,CAAA;QAEF,MAAM,aAAa,GAAG,UAAU,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,OAAO,IAAI,IAAI,CAAA;QAEnE,IAAI,CAAC;YACD,MAAM,MAAM,GAAG,IAAI,CAAC,KAAK,CAAC,aAAa,CAA+B,CAAA;YACtE,MAAM,GAAG,MAAM,CAAC,UAAU,IAAI,EAAE,CAAA;QACpC,CAAC;QAAC,OAAO,GAAG,EAAE,CAAC;YACX,KAAK,GAAG,IAAA,uBAAc,EAAC,GAAG,CAAC,CAAA;YAC3B,OAAO,CAAC,KAAK,CAAC,gCAAgC,KAAK,EAAE,CAAC,CAAA;QAC1D,CAAC;IACL,CAAC;IAAC,OAAO,GAAG,EAAE,CAAC;QACX,KAAK,GAAG,IAAA,uBAAc,EAAC,GAAG,CAAC,CAAA;QAC3B,OAAO,CAAC,KAAK,CAAC,wBAAwB,KAAK,EAAE,CAAC,CAAA;IAClD,CAAC;IAED,OAAO;QACH,GAAG,EAAE;YACD,QAAQ,EAAE,KAAK;YACf,KAAK;SACR;QACD,QAAQ,EAAE,MAAM;QAChB,KAAK;KACR,CAAA;AACL,CAAC","sourcesContent":["import OpenAI from 'openai'\nimport { zodResponseFormat } from 'openai/helpers/zod'\nimport { LlmProcessOutput, LlmProcessProps, Strategy } from '../../types'\nimport { StrategiesZodSchema } from './structures/zod'\nimport { stringifyError } from '../errors'\n\nexport const XAI_MODELS = {\n    grok2latest: 'grok-2-latest',\n    grok3latest: 'grok-3-latest'\n}\n\nconst apiClient = new OpenAI({\n    apiKey: process.env.X_AI_API_KEY || '',\n    baseURL: 'https://api.x.ai/v1'\n})\n\nexport async function callGrok(llmInput: LlmProcessProps): Promise<LlmProcessOutput> {\n    let output = null\n    let error = null\n    const model = llmInput.model || XAI_MODELS.grok3latest\n\n    try {\n        const completion = await apiClient.chat.completions.create({\n            model,\n            store: true,\n            messages: [\n                {\n                    role: 'system',\n                    content:\n                        'You are an expert in cryptocurrencies, DeFi applications and their use cases. Return output in JSON format.'\n                },\n                { role: 'user', content: llmInput.prompt }\n            ],\n            response_format: zodResponseFormat(StrategiesZodSchema, 'strategies')\n        })\n\n        const outputContent = completion.choices[0].message.content || '{}'\n\n        try {\n            const parsed = JSON.parse(outputContent) as { strategies: Strategy[] }\n            output = parsed.strategies || []\n        } catch (err) {\n            error = stringifyError(err)\n            console.error(`Invalid JSON in Grok output: ${error}`)\n        }\n    } catch (err) {\n        error = stringifyError(err)\n        console.error(`Error querying Grok: ${error}`)\n    }\n\n    return {\n        llm: {\n            provider: 'xAI',\n            model\n        },\n        response: output,\n        error\n    }\n}\n"]}